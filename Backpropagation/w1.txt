Wed Sep 13 03:43:45 2017

Input to hidden weights: 
Input 0: -1.67201 -1.12827 0.347199 -0.34575 0.327318 -1.01577 -0.730702 0.0919792 0.433186 -0.828768
Input 1: 1.10676 1.12419 -0.312526 0.327775 -0.064714 1.12081 0.980297 -0.0542087 -0.485329 0.442636
Input 2: 0.47832 0.500045 0.113017 -0.0892854 -0.0422274 0.507137 0.529738 0.222476 -0.196775 0.187467
Input 3: -0.0295337 -0.130738 0.274929 -0.272421 0.612427 -0.159457 -0.706354 -0.159195 -0.00725239 0.698437
Input 4: 0.694142 0.678086 -0.52779 0.506726 -0.172385 0.666709 0.588833 -0.257428 -0.427478 0.156824
Input 5: 0.147824 0.23844 -0.212594 0.207579 -0.543679 0.263802 0.557565 -0.0327348 -0.300343 -0.376744
Input 6: 0.214972 0.373439 0.835237 -0.777678 0.297295 0.33018 0.148554 0.550544 0.114296 0.271366
Input 7: 0.0422833 0.279044 -1.10918 1.06333 -0.217944 0.351748 0.522501 -0.689226 -0.496453 -0.339285
Input 8: -0.496808 -0.197478 -1.27974 1.21613 -0.283156 -0.101549 0.228745 -0.818956 -0.410574 -0.80838
Input 9: 1.24556 0.933871 0.461279 -0.39313 -1.24713 0.883083 1.30094 0.624154 -0.414303 -0.0210671
Input 10: -1.11204 -1.13453 0.253202 -0.269834 -0.0338378 -1.12927 -0.966151 0.0393674 0.494208 -0.554866
Input 11: -0.928456 -0.766973 0.153526 -0.15682 -0.702706 -0.724414 -0.204383 0.126478 0.289023 -1.05364
Input 12: -0.00723042 0.0976398 0.00782429 0.0363519 -1.17091 0.141379 0.936259 0.427695 -0.0720261 -1.17775
Input 13: -0.408318 -0.399449 0.313428 -0.297992 0.190162 -0.392664 -0.425504 0.114414 0.312192 0.00463505
Input 14: -0.0822886 -0.0397505 0.224869 -0.201139 0.0105567 -0.0348026 -0.0496105 0.172568 0.201027 -0.0281891
Input 15: 0.0025657 -0.0809887 -0.337417 0.334288 -0.69829 -0.0248754 0.311284 -0.158766 -0.262313 -0.380545
Input 16: 0.262523 -0.0646458 0.927407 -0.886364 0.338983 -0.159514 -0.519537 0.544358 0.412046 0.614699
Input 17: 0.572552 0.251038 1.30864 -1.23589 0.117209 0.150594 -0.130639 0.882562 0.383658 0.731518
Input 18: 0.305733 0.51279 -0.721158 0.705725 -0.376671 0.57086 0.761676 -0.296234 -0.195019 -0.354159
Input 19: -0.0235087 -0.00377157 -0.150601 0.137911 0.195943 -0.00314749 -0.102555 -0.162926 0.00538942 0.116814
Input 20: -0.0936771 0.0357912 -0.071753 0.074134 -0.0182078 0.0681201 0.163019 -0.0341652 0.00511114 -0.135535
Input 21: 0.2343 0.445639 -0.144109 0.142749 -0.07533 0.485038 0.576603 0.0410243 -0.0340393 -0.0665051
Input 22: 0.210955 0.17274 -0.193885 0.183566 0.168781 0.163022 0.000688178 -0.168194 -0.0608448 0.242858
Input 23: 0.102698 0.12233 -0.152303 0.146092 0.119209 0.128617 0.0627128 -0.109845 -0.0226896 0.12054
Input 24: 0.0834185 0.181673 -0.308228 0.297537 0.000806287 0.21274 0.242646 -0.0995095 0.00508587 -0.130464
Input 25: 0.0356244 0.0628869 -0.0348929 0.0301517 0.179595 0.0648933 -0.0271077 -0.059319 0.00804144 0.128333
Input 26: -0.011799 0.0492292 -0.0246784 0.0239291 0.138748 0.061648 0.0285585 -0.0327635 0.0125003 0.062803

Hidden layer bias: 
-0.495927 -0.383295 0.400923 -0.376887 -0.40644 -0.350836 0.0577652 0.367549 0.151552 -0.595188

Hidden to output weights: 
Hidden 0: -0.597134 -0.566899 1.68486 0.838988
Hidden 1: -0.137274 -1.13035 1.6553 0.935315
Hidden 2: -0.017278 0.435928 0.718899 -1.37776
Hidden 3: 0.0232918 -0.51679 -0.614052 1.39588
Hidden 4: -0.486982 1.03659 0.427807 -0.0142062
Hidden 5: -0.0782009 -1.22097 1.5787 0.995319
Hidden 6: 0.324385 -1.49572 1.01912 0.930981
Hidden 7: 0.101722 0.107896 0.49205 -1.0016
Hidden 8: 0.587711 1.08759 -0.119201 -1.1832
Hidden 9: -0.842481 0.489229 1.34334 0.382495

Output layer bias: 
1.53992 -0.0917082 0.496135 0.219656

Wed Sep 13 03:44:06 2017

Input to hidden weights: 
Input 0: -1.2883 1.11167 -1.19066 0.295229 -0.512562 0.674024 -0.433144 0.591 -0.500397 1.03792
Input 1: 0.906007 -0.749649 0.964764 -0.319196 0.238645 -0.887578 0.572955 -0.853791 0.397878 -0.658739
Input 2: 0.387835 -0.32199 0.416422 0.225306 0.334923 -0.400564 0.277513 -0.404846 0.00455465 -0.275976
Input 3: 0.00581774 -0.25246 -0.110819 0.344507 -0.788284 0.385861 -0.180137 0.446496 -0.171257 -0.317204
Input 4: 0.561066 -0.443875 0.598224 -0.708779 0.0633419 -0.561425 0.448353 -0.548061 0.372388 -0.374952
Input 5: 0.0585043 0.0652099 0.132561 -0.353012 0.615353 -0.372751 0.413295 -0.428149 0.165638 0.125819
Input 6: 0.243416 -0.256348 0.284716 1.31318 -0.200472 -0.304415 -0.0323824 -0.239739 -0.266102 -0.232151
Input 7: 0.048507 0.0523363 0.162948 -1.63387 -0.0933241 -0.431882 0.505745 -0.481533 0.658148 0.100239
Input 8: -0.413888 0.490676 -0.280626 -1.94151 -0.0891373 -0.120776 0.375162 -0.211237 0.610914 0.528927
Input 9: 0.877629 -0.590105 0.865393 0.772598 1.81772 -0.796919 0.643647 -0.839665 0.243525 -0.468766
Input 10: -0.922331 0.796471 -0.969523 0.174882 -0.159901 0.858945 -0.534322 0.822346 -0.356168 0.71657
Input 11: -0.837265 0.893441 -0.770638 0.00156188 0.651225 0.345638 -0.156676 0.260049 -0.149077 0.883983
Input 12: -0.0885947 0.431536 0.0589511 0.0225826 1.46803 -0.437975 0.386202 -0.566053 0.244114 0.553003
Input 13: -0.312189 0.226344 -0.340332 0.41745 -0.149686 0.339431 -0.311689 0.347138 -0.184785 0.172383
Input 14: -0.050885 0.0492127 -0.0479929 0.32679 0.0469832 0.0365736 -0.147552 0.0469332 -0.0541396 0.037221
Input 15: -0.0652599 0.156624 -0.0742211 -0.568274 0.757934 0.00620489 0.283585 -0.0868435 0.292181 0.180945
Input 16: 0.223866 -0.32929 0.0811553 1.40581 -0.118987 0.345492 -0.450473 0.425183 -0.497059 -0.369543
Input 17: 0.460213 -0.510395 0.327421 1.97357 0.298177 0.0827436 -0.316108 0.162149 -0.570687 -0.531028
Input 18: 0.234881 -0.063575 0.351758 -1.05666 0.224268 -0.732781 0.411939 -0.753463 0.455766 -0.0013503
Input 19: 0.00784192 -0.0325834 0.00726494 -0.206776 -0.286213 0.00748046 -0.0429082 0.0281468 0.0301874 -0.0469413
Input 20: -0.0660218 0.0997636 -0.0190594 -0.120697 -0.0444124 -0.176879 0.0640289 -0.183968 0.0310623 0.101113
Input 21: 0.194011 -0.0906056 0.28444 -0.164277 0.0838221 -0.604813 0.183911 -0.588576 0.0825066 -0.0657901
Input 22: 0.199025 -0.207648 0.185768 -0.259165 -0.275644 -0.0997217 0.0345111 -0.0691825 0.121923 -0.209017
Input 23: 0.109665 -0.105369 0.115388 -0.21667 -0.213473 -0.135137 0.0309438 -0.11611 0.0782888 -0.108336
Input 24: 0.0594278 0.00624635 0.110162 -0.467859 -0.0767589 -0.31514 0.0972229 -0.311337 0.102304 0.0214767
Input 25: 0.0487201 -0.0513008 0.057467 -0.0275763 -0.223017 -0.0697812 -0.02046 -0.0438215 -0.0084994 -0.0625348
Input 26: 0.0113607 -0.00468619 0.0311371 -0.0150548 -0.175482 -0.105022 -0.00190989 -0.0898502 -0.00970495 -0.0149379

Hidden layer bias: 
-0.467412 0.499835 -0.426467 0.518192 0.634517 0.178545 -0.0683835 0.107555 -0.272967 0.502958

Hidden to output weights: 
Hidden 0: -0.377577 -0.391995 1.31221 0.767391
Hidden 1: 0.424392 0.0428247 -1.1489 -0.699962
Hidden 2: -0.27311 -0.720676 1.34314 0.859432
Hidden 3: -0.120683 0.541508 1.36118 -1.93119
Hidden 4: 0.922656 -1.05553 -0.262406 -0.320446
Hidden 5: -0.109663 1.30683 -1.10924 -0.943255
Hidden 6: -0.377607 -1.3668 0.147938 1.1431
Hidden 7: -0.0844775 1.35386 -0.914264 -0.961891
Hidden 8: -0.188143 -0.937763 0.115957 1.4464
Hidden 9: 0.433102 -0.0991406 -1.13359 -0.682796

Output layer bias: 
1.67086 -0.0619656 0.448761 0.0201832

Wed Sep 13 03:58:40 2017

Input to hidden weights: 
Input 0: -0.916429 -0.592809 -1.06338 0.318052 -1.14427 0.620887 -1.0255 -0.332318 -0.375913 0.565663
Input 1: 0.394915 0.421624 1.01606 -0.261402 1.15974 -0.43594 1.12546 0.0325884 0.342959 -0.596326
Input 2: 0.311194 0.00493585 0.417465 0.206169 0.506224 -0.0168069 0.496162 0.107957 -0.120646 -0.265608
Input 3: 0.946232 -0.0743534 -0.263388 0.0524777 -0.155131 0.0720527 -0.18657 -0.730189 -0.104957 -0.0565233
Input 4: 0.154424 0.360744 0.616939 -0.388577 0.698428 -0.368858 0.664898 0.0987816 0.426476 -0.435523
Input 5: -0.388281 0.105034 0.333453 -0.173403 0.26182 -0.10262 0.308667 0.571926 0.180513 -0.261659
Input 6: 0.336247 -0.280859 0.514645 0.75559 0.346046 0.248393 0.357856 -0.394863 -0.797428 0.0563443
Input 7: -0.791727 0.556053 0.242979 -0.941211 0.327746 -0.531861 0.355543 0.138241 0.95411 -0.410335
Input 8: -1.39263 0.48922 -0.213473 -1.08394 -0.151654 -0.448472 -0.0997644 0.191731 1.07435 -0.24491
Input 9: 0.317922 0.218257 1.10605 0.464386 0.979761 -0.263291 0.989059 1.55586 -0.404961 -0.506489
Input 10: -0.511296 -0.429433 -0.980555 0.221404 -1.14497 0.449352 -1.10264 0.0539898 -0.307023 0.614688
Input 11: -1.13318 -0.288114 -0.447086 0.0956674 -0.738221 0.308019 -0.622815 0.815399 -0.187622 0.418284
Input 12: -1.30251 0.0372163 0.298407 0.275461 0.192805 -0.0473269 0.244133 1.39348 -0.214132 0.00572492
Input 13: -0.0465216 -0.185718 -0.343392 0.193664 -0.390455 0.19547 -0.370422 -0.173072 -0.225174 0.295492
Input 14: -0.0241404 -0.0842642 0.0111325 0.227812 -0.00509436 0.0826965 0.0042579 0.0431509 -0.226916 0.166956
Input 15: -0.167165 0.24199 -0.143481 -0.263984 -0.00636398 -0.238723 0.0110969 0.86943 0.318101 -0.213337
Input 16: 1.04905 -0.393698 -0.07973 0.785069 -0.091745 0.368232 -0.158987 -0.323511 -0.790799 0.301936
Input 17: 1.34291 -0.482612 0.29218 1.14196 0.22605 0.440657 0.175264 0.0109621 -1.12638 0.21837
Input 18: -0.726449 0.318093 0.712323 -0.574069 0.617755 -0.289545 0.700805 0.35337 0.588895 -0.22752
Input 19: 0.0521387 0.0508937 -0.0427226 -0.162335 -0.025632 -0.0430782 -0.0339343 -0.257061 0.157739 0.00737735
Input 20: -0.221085 -0.00499698 0.104251 -0.0725405 0.0437755 0.0155527 0.0876196 0.0154969 0.0706925 0.00558634
Input 21: -0.164118 0.0308313 0.620408 -0.0745508 0.479545 -0.0206723 0.558419 0.0425288 0.0904546 -0.0771637
Input 22: 0.194526 0.135866 0.136248 -0.189441 0.183626 -0.133328 0.160129 -0.234467 0.190971 -0.084811
Input 23: 0.0460889 0.072481 0.13313 -0.147832 0.130849 -0.0658111 0.137055 -0.150299 0.148133 -0.0409231
Input 24: -0.338101 0.0662964 0.276789 -0.250431 0.217819 -0.0461283 0.264113 0.0110514 0.262767 -0.0316523
Input 25: 0.121231 0.0168045 0.0518606 -0.0512994 0.0510087 -0.0148383 0.0479068 -0.241961 0.0515954 0.000378742
Input 26: 0.0342227 0.00540623 0.0566053 -0.0406622 0.0388857 -0.000239438 0.0518214 -0.179402 0.0420976 0.00535035

Hidden layer bias: 
-0.512959 -0.314567 -0.267005 0.397971 -0.399094 0.316455 -0.332265 0.571382 -0.399583 0.202262

Hidden to output weights: 
Hidden 0: -1.04175 0.896246 1.69131 -0.108855
Hidden 1: -0.281892 -0.617472 0.133255 1.31725
Hidden 2: 0.0443841 -1.39266 1.96706 0.80066
Hidden 3: 0.00285101 0.178277 0.617134 -1.31947
Hidden 4: -0.209175 -1.34305 1.80294 1.02891
Hidden 5: 0.32377 0.646938 -0.166094 -1.30918
Hidden 6: -0.0970494 -1.44622 1.79622 1.00125
Hidden 7: 0.726473 -1.31516 -0.350573 -0.32978
Hidden 8: -0.0674412 -0.200528 -0.588208 1.39103
Hidden 9: 0.575908 1.10416 -0.365294 -1.0782

Output layer bias: 
1.71885 -0.407396 0.56657 0.177281

Wed Sep 13 04:14:27 2017

Input to hidden weights: 
Input 0: -0.974736 -1.42894 -1.3028 -0.148337 -0.626785 0.340591 -0.513947 -0.676956 -1.09745 0.50853
Input 1: 0.774638 0.904726 0.877964 0.172014 0.325945 -0.200007 0.29075 0.266843 0.900204 -0.356782
Input 2: 0.336268 0.301352 0.320066 -0.0388793 -0.0438371 -9.65535e-05 -0.081671 0.0430129 0.423558 -0.134438
Input 3: -0.153922 -0.259915 -0.181156 0.603857 -0.0896478 -0.420449 -0.0647128 0.18809 -0.42152 -0.110406
Input 4: 0.450777 0.492663 0.484472 0.0424841 0.47621 -0.0711704 0.521389 0.172539 0.470468 -0.355438
Input 5: 0.173862 0.118437 0.107168 -0.375492 0.15828 0.28717 0.19471 -0.126561 0.248729 -0.236676
Input 6: -0.00356821 0.438974 0.236768 0.53978 -0.609999 -0.459077 -0.721548 0.356727 0.203799 0.175103
Input 7: 0.320491 0.220314 0.238587 -0.185609 0.926169 0.202844 1.09019 -0.179918 0.336835 -0.389265
Input 8: 0.0193258 -0.199286 -0.15935 -0.467639 0.883543 0.487106 1.10553 -0.464885 0.0307903 -0.28657
Input 9: 0.743284 1.11567 0.977413 -0.482222 -0.293372 0.121102 -0.533098 0.368031 0.98811 -0.274494
Input 10: -0.815784 -0.916636 -0.912561 -0.279418 -0.315508 0.299979 -0.264552 -0.32712 -0.899388 0.37092
Input 11: -0.627145 -0.611313 -0.678164 -0.643112 -0.387717 0.547183 -0.358614 -0.421027 -0.552399 0.325053
Input 12: 0.156233 0.188417 0.147447 -0.90802 -0.180845 0.666136 -0.252205 -0.344055 0.40102 0.115346
Input 13: -0.313734 -0.31527 -0.311557 0.0829739 -0.232461 -0.0233345 -0.247544 -0.0905072 -0.344842 0.257578
Input 14: -0.155101 -0.0826366 -0.105917 -0.0255798 -0.221385 0.0311343 -0.248446 -0.0740761 -0.113514 0.248301
Input 15: 0.0660806 -0.425283 -0.181875 -0.476659 0.289404 0.40455 0.330188 -0.314074 -0.215606 -0.186773
Input 16: -0.169241 -0.0353438 -0.0465188 0.369638 -0.700361 -0.347445 -0.847548 0.298763 -0.224848 0.28569
Input 17: 0.00291834 0.22128 0.177832 0.319324 -0.934888 -0.371387 -1.16332 0.397742 0.0211127 0.286274
Input 18: 0.179272 0.315696 0.225449 -0.272312 0.455321 0.209402 0.533911 -0.103848 0.386719 -0.0633615
Input 19: 0.00655991 0.0158709 0.0252863 0.21899 0.150182 -0.165459 0.172089 0.104355 -0.0464144 -0.0295181
Input 20: -0.0191048 0.024691 -0.0130385 -0.0410048 0.0270091 0.0380777 0.0323575 -0.0267397 0.0539477 0.0344741
Input 21: 0.126234 0.268319 0.206054 0.197786 0.150368 -0.170717 0.171291 0.147532 0.208828 -0.00928006
Input 22: 0.12027 0.157324 0.15911 0.229343 0.23642 -0.179218 0.26211 0.135317 0.0828541 -0.0890597
Input 23: 0.0667588 0.117856 0.0974021 0.13602 0.142259 -0.110668 0.15605 0.0874837 0.0854362 -0.031855
Input 24: 0.0766625 0.202373 0.124976 -0.139545 0.172289 0.0772473 0.200143 -0.00603206 0.232151 0.0151695
Input 25: 0.0560866 0.116498 0.0998723 0.191032 0.129072 -0.149595 0.140174 0.11644 0.0437514 -0.0350509
Input 26: 0.0450208 0.103499 0.0822747 0.158217 0.0935687 -0.129661 0.0965786 0.102673 0.051194 -0.0170714

Hidden layer bias: 
-0.248176 -0.302044 -0.327007 -0.56416 -0.514827 0.441096 -0.56551 -0.318576 -0.118682 0.203692

Hidden to output weights: 
Hidden 0: -0.384535 -1.38448 0.841899 1.14464
Hidden 1: -0.0328599 -1.68119 1.81313 0.99965
Hidden 2: -0.267892 -1.4994 1.4319 1.08291
Hidden 3: -0.512139 0.760854 0.712787 0.415446
Hidden 4: -0.53799 -0.507127 -0.497591 1.46045
Hidden 5: 0.250945 -0.694482 -0.876654 -0.386277
Hidden 6: -0.544279 -0.433545 -0.856905 1.57748
Hidden 7: 0.028318 0.465352 1.05635 0.460182
Hidden 8: 0.0238272 -1.72365 1.30768 1.05768
Hidden 9: 0.446786 0.797521 -0.00877675 -1.01195

Output layer bias: 
1.89227 -0.392395 0.952131 0.114065

Wed Sep 13 04:14:59 2017

Input to hidden weights: 
Input 0: -0.80921 -0.421191 0.236948 0.131908 -0.033187 -0.164996 0.0323129 0.156411 1.88714 -0.668444
Input 1: 0.761678 0.347927 -0.256705 -0.205485 0.177059 0.108839 -0.200536 -0.143911 -1.14251 0.552217
Input 2: 0.480735 0.0290982 -0.0206065 0.0470828 0.0620481 0.0252346 -0.075619 -0.0430866 -0.54291 0.391028
Input 3: -0.454378 -0.276893 0.200328 0.197962 0.193952 -0.112888 -0.229124 0.0624264 0.395247 -0.521006
Input 4: 0.527248 0.393862 -0.295971 -0.289263 0.0300651 0.0750169 -0.0293792 -0.0883239 -0.722084 0.480171
Input 5: 0.387098 0.24201 -0.20494 -0.209234 -0.232498 -0.045042 0.266442 0.0554652 -0.113697 0.468666
Input 6: -0.0967774 -0.616657 0.484552 0.520997 0.362711 0.109743 -0.42448 -0.133047 -0.380371 -0.181893
Input 7: 0.219268 0.632263 -0.534792 -0.647668 0.0122168 0.0205192 0.00555817 -0.0535103 0.0569478 0.171824
Input 8: 0.0564909 0.58133 -0.527817 -0.695089 -0.153552 -0.0496742 0.195373 0.0313477 0.648288 0.121656
Input 9: 0.687909 -0.119805 0.179364 0.367912 -0.415326 -0.00437242 0.460434 0.0780376 -1.24558 0.787012
Input 10: -0.731232 -0.40191 0.303425 0.268906 -0.226878 -0.114049 0.255357 0.159956 1.14438 -0.506242
Input 11: -0.446574 -0.398711 0.295222 0.279464 -0.498002 -0.130809 0.562549 0.211505 1.0903 -0.156991
Input 12: 0.427943 -0.0755246 0.0885783 0.174372 -0.450539 0.00937255 0.498311 0.082537 -0.231596 0.607888
Input 13: -0.446903 -0.292301 0.218594 0.203259 0.0164949 -0.0414937 -0.0197839 0.0509714 0.599116 -0.446886
Input 14: -0.280185 -0.391747 0.31378 0.347468 -0.0163531 0.00372583 0.0123734 0.0240477 0.360353 -0.275451
Input 15: -0.070977 0.459634 -0.35064 -0.355366 -0.405273 -0.191864 0.459815 0.220539 0.426293 0.0556164
Input 16: -0.205646 -0.539943 0.476217 0.586848 0.11556 0.0126552 -0.149665 0.00520002 -0.310344 -0.224043
Input 17: -0.0646997 -0.67054 0.603884 0.79551 0.0994516 0.0260122 -0.13754 0.00208547 -0.646747 -0.101003
Input 18: 0.27325 0.138267 -0.115472 -0.132102 -0.00780507 0.0957717 0.0223487 -0.085676 -0.060591 0.218437
Input 19: 0.0441448 0.0830835 -0.0662437 -0.0819072 0.0710259 0.0400767 -0.0745716 -0.0467447 -0.0945866 0.00142216
Input 20: 0.102531 0.00661391 -0.00931332 -0.0069705 -0.00149959 0.0404671 0.00829042 -0.0340127 0.0125686 0.0775892
Input 21: 0.0538097 0.164467 -0.127062 -0.164581 0.225416 0.0867805 -0.241413 -0.114268 -0.279006 -0.0566498
Input 22: 0.0474127 0.124129 -0.0935417 -0.110625 0.116397 0.047346 -0.12659 -0.0613635 -0.179909 -0.0230996
Input 23: 0.045448 0.0974351 -0.0755901 -0.0932 0.101379 0.0507315 -0.107457 -0.0616377 -0.105632 -0.0122501
Input 24: 0.192178 0.0980936 -0.0855748 -0.109101 0.0152051 0.0839805 0.00135117 -0.0790848 0.0108488 0.154165
Input 25: 0.0393464 0.111823 -0.0874682 -0.108762 0.0923616 0.0435456 -0.0968552 -0.0551419 -0.1138 -0.0141894
Input 26: 0.0365534 0.109403 -0.0866327 -0.110372 0.0880435 0.0452544 -0.0906995 -0.0558856 -0.074677 -0.012487

Hidden layer bias: 
-0.0702991 -0.287976 0.219213 0.259125 -0.257797 -0.0908514 0.285888 0.125879 0.397515 0.076847

Hidden to output weights: 
Hidden 0: -0.0796987 -1.55222 1.05017 0.896661
Hidden 1: -0.593017 -0.84475 -0.47704 1.35513
Hidden 2: 0.290151 0.67737 0.466958 -1.09409
Hidden 3: 0.246988 0.539186 0.73512 -1.1592
Hidden 4: -0.11959 0.591173 0.498901 0.505594
Hidden 5: 0.31665 0.304695 0.48119 0.539088
Hidden 6: 0.230702 -0.596941 -0.556384 -0.502788
Hidden 7: -0.237866 -0.337128 -0.449018 -0.612434
Hidden 8: 1.31126 1.29661 -2.12217 -0.941161
Hidden 9: 0.242779 -1.15442 0.742751 0.659594

Output layer bias: 
1.17104 0.213151 0.834879 0.130446

Wed Sep 13 04:15:30 2017

Input to hidden weights: 
Input 0: 0.120585 0.0996805 -0.646882 0.137638 1.07487 0.503927 2.10322 1.01784 -0.439037 -0.259298
Input 1: -0.143694 -0.0652408 0.711976 0.108564 -0.888606 -0.533049 -1.26361 -0.998682 0.271839 0.173374
Input 2: -0.00518694 0.0511808 0.660768 -0.557194 -0.361564 0.100182 -0.477868 -0.505645 0.120014 0.0413479
Input 3: -0.0470659 0.115756 -1.24898 -0.769286 0.28035 0.349584 0.394434 0.0147227 -0.146787 -0.168875
Input 4: -0.015393 -0.00687649 0.779844 0.344957 -0.515596 -0.431938 -0.778661 -0.462606 0.203279 0.10479
Input 5: 0.241548 0.201282 1.14758 0.395542 -0.144784 -0.205134 -0.0820578 -0.137791 -0.0445732 -0.0983929
Input 6: -0.284784 -0.0588058 -0.878484 -0.881427 -0.223235 0.424637 -0.474493 0.0318686 0.36844 0.171582
Input 7: -0.0421618 -0.0976609 0.253065 1.37685 -0.192171 -0.763466 0.0531027 -0.133179 -0.0263636 0.0264715
Input 8: 0.125046 0.0104119 0.499789 1.75364 0.177048 -0.684407 0.771369 0.293894 -0.205918 -0.101363
Input 9: 0.344926 0.296717 1.38489 -0.948905 -0.533492 0.303558 -1.30135 -0.547921 0.150629 -0.0355531
Input 10: 0.190941 0.109353 -0.686621 -0.17371 0.849611 0.567358 1.22118 0.991387 -0.265985 -0.185783
Input 11: 0.415884 0.260388 0.30138 0.254081 0.605561 0.376903 1.05695 0.907213 -0.262795 -0.217116
Input 12: 0.349551 0.169289 1.42118 0.313859 -0.0928193 0.0397089 -0.174953 0.0445607 -0.0371865 -0.0348005
Input 13: -0.0313378 -0.0444981 -0.782275 -0.113064 0.350549 0.246993 0.617698 0.361751 -0.145018 -0.0475322
Input 14: -0.0053926 -0.0386193 -0.433809 -0.371168 0.157256 0.35161 0.343187 0.299635 -0.00558618 0.0305539
Input 15: 0.394664 0.199987 0.435204 0.541088 0.435503 -0.218863 0.522649 -0.109599 -0.56196 -0.342862
Input 16: -0.0694191 0.0240846 -0.602714 -1.29073 0.039906 0.583399 -0.38382 -0.0824348 0.0807338 0.0215788
Input 17: -0.061092 0.0554312 -0.459825 -1.88831 -0.15571 0.771165 -0.805536 -0.323433 0.173419 0.0551451
Input 18: -0.0682306 -0.116581 0.644932 0.469299 -0.341159 -0.268639 -0.084291 0.04657 0.223842 0.1922
Input 19: -0.0830524 -0.0793437 -0.0305193 0.119459 -0.103318 -0.110837 -0.0948595 -0.0356846 0.0712556 0.0742679
Input 20: -0.0394627 -0.050859 0.212444 -0.091683 -0.0813633 0.04929 0.0663407 0.0905452 0.0949591 0.0867219
Input 21: -0.253796 -0.203322 -0.174061 -0.0155321 -0.264182 -0.173445 -0.440327 -0.202032 0.182915 0.167788
Input 22: -0.119999 -0.100116 -0.224349 0.162544 -0.159573 -0.186982 -0.212233 -0.121451 0.0806993 0.0810565
Input 23: -0.126649 -0.109795 -0.161187 0.0701096 -0.104345 -0.109811 -0.0984299 -0.0221762 0.0958241 0.0959031
Input 24: -0.100806 -0.129532 0.533081 0.13164 -0.204779 -0.0668303 0.015689 0.146092 0.217609 0.183191
Input 25: -0.105789 -0.0944764 -0.102206 0.0884025 -0.119356 -0.118008 -0.135968 -0.0548494 0.0838946 0.0818645
Input 26: -0.110103 -0.102005 -0.0675613 0.0916694 -0.0896158 -0.106359 -0.072478 -0.00632061 0.088248 0.0886723

Hidden layer bias: 
0.251911 0.209136 0.516606 -0.432124 0.319039 0.451892 0.472049 0.295634 -0.14085 -0.15127

Hidden to output weights: 
Hidden 0: -0.435206 -0.885453 -0.821716 -0.459975
Hidden 1: -0.601418 -0.793136 -0.503656 -0.483927
Hidden 2: 1.05435 -1.64964 0.534836 0.414679
Hidden 3: 0.598317 -0.849089 -1.39645 2.13538
Hidden 4: 0.0478709 0.865554 -1.3084 -0.935255
Hidden 5: 0.0994049 0.632229 0.10878 -1.72627
Hidden 6: 0.874338 0.727217 -2.17219 -0.888269
Hidden 7: 0.898968 0.848193 -0.91855 -1.14081
Hidden 8: 0.682296 0.555972 1.10117 0.699079
Hidden 9: 0.781431 0.671669 0.869589 0.631242

Output layer bias: 
0.805685 -0.218744 0.726195 0.0737655

Wed Sep 13 04:16:07 2017

Input to hidden weights: 
Input 0: -0.32125 2.85115 1.69175 -0.265912 0.60637 2.21639 -0.713114 0.223853 2.2613 -0.762139
Input 1: -0.654308 -1.5163 -3.0975 -0.61234 -1.5931 -1.28885 -0.95514 -0.443467 -1.39994 0.233872
Input 2: -1.3247 -0.208913 -1.36139 1.08764 -0.587847 -0.360992 -0.0519206 0.455286 -0.6666 0.263583
Input 3: 2.37492 0.445715 1.58753 1.57839 -0.624309 0.800681 0.696343 -1.71731 0.239079 -1.22458
Input 4: -0.951143 -1.15006 -1.02016 -0.710067 -0.00979916 -1.03413 -0.0458746 0.70187 -0.727991 0.730073
Input 5: -2.33755 -0.180311 -1.1447 -0.670077 0.0326979 -0.408612 -0.996887 1.23909 -0.386043 0.415292
Input 6: 1.81119 -0.700203 0.452131 1.28481 -0.450288 -0.35433 1.76192 -1.45797 -0.0862791 -0.223651
Input 7: -0.40139 -0.287739 0.571021 -2.38716 -0.00397944 -0.14123 -1.93443 0.480207 -0.779904 -0.0421822
Input 8: -1.01257 0.620613 1.32245 -3.42932 0.377432 0.521822 -2.97306 0.857364 -0.491658 0.0866493
Input 9: -1.46439 -1.51276 -1.06737 2.02077 0.22535 -1.62014 1.06034 1.0456 -1.65213 0.963971
Input 10: 0.93749 1.15551 3.26538 0.592873 1.49881 1.09152 1.15343 0.335576 1.09155 -0.294863
Input 11: -0.691539 -0.110693 1.88326 -0.578628 1.14301 0.239856 -0.553015 1.06422 -0.332226 -0.165911
Input 12: -2.09872 0.179526 -0.594218 -1.08071 0.792124 -0.609253 -0.377559 1.89761 0.0328385 1.03724
Input 13: 0.937897 0.880673 1.16159 0.0310171 -0.153154 0.947575 -0.461433 -0.69594 0.387153 -0.893773
Input 14: 0.590351 0.00275445 1.61208 0.345364 0.281977 0.390767 -0.209913 -0.0130825 -0.467219 -0.515412
Input 15: -0.304719 1.40143 -0.599985 -1.24209 -0.0526525 0.559031 -0.75258 0.747699 1.10416 0.0439633
Input 16: 1.60994 -0.0785724 -0.794275 1.87158 -0.438826 -0.112829 2.34024 -1.26298 0.80604 -0.0379889
Input 17: 1.26642 -0.853382 -1.51587 3.40783 -0.504597 -0.731098 3.23311 -0.964028 0.378819 -0.0417097
Input 18: -1.53165 -0.740704 0.458188 -0.663699 0.327005 -0.252667 -1.56357 0.469422 -1.27353 0.0876244
Input 19: -0.226145 -0.0327159 0.00672692 -0.162284 -0.0591943 0.0353608 -0.345345 0.0423609 -0.0486216 -0.0686634
Input 20: -0.754547 0.456282 0.424588 0.722851 0.204859 0.306675 -0.265272 0.0799175 0.149015 -0.0730714
Input 21: 0.771224 -1.08022 -1.81866 -0.126869 -1.01659 -0.666744 0.764798 -1.30284 -0.329658 0.20164
Input 22: 0.468972 -0.190437 0.137974 -0.414991 -0.208792 -0.0609127 -0.136882 -0.397736 -0.118496 -0.134311
Input 23: 0.243653 0.0736489 0.261053 0.133661 0.0209298 0.0758463 0.013333 -0.426248 0.0711739 -0.0104831
Input 24: -1.63483 -0.431493 0.386904 0.624399 0.576018 -0.120252 -0.802246 0.38695 -0.973359 0.314939
Input 25: -0.202888 -0.0877289 0.0672771 0.187502 0.00679835 0.0235398 -0.148554 0.034839 -0.104589 -0.0700577
Input 26: -0.311796 0.0859831 0.160307 0.297015 0.150474 0.123381 -0.166643 0.0441137 0.0102781 -0.00228152

Hidden layer bias: 
-1.21476 0.389624 -0.0916025 1.14935 0.510582 0.136538 0.212605 0.824722 0.11263 0.271095

Hidden to output weights: 
Hidden 0: -3.59444 -0.0465663 -0.960137 -1.17225
Hidden 1: -1.22993 0.267341 -3.46497 -1.53256
Hidden 2: 0.400369 -4.02121 -3.27024 -1.45465
Hidden 3: -0.706862 0.601657 0.933942 -4.22329
Hidden 4: 0.920565 0.440676 -0.148927 -1.74941
Hidden 5: -1.46983 -1.8827 -2.90227 -1.77469
Hidden 6: -2.02643 0.265382 0.653492 -3.42654
Hidden 7: 0.947699 -1.34308 -1.55192 0.792203
Hidden 8: -2.29556 -0.00701341 -2.86896 -1.99497
Hidden 9: 1.35014 2.25223 0.951046 1.17868

Output layer bias: 
1.15116 0.092082 0.527243 -0.0210631

