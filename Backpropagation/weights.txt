

Tue Sep 12 22:12:54 2017

Input to hidden weights: 
Input 0: 0.277741 -0.401117 -0.246151 -0.679868 -0.835837 -0.3618 1.42514 -0.83555 -0.0572313 1.44802
Input 1: -0.0667301 0.335633 0.301224 0.935313 1.02475 0.308067 -0.956296 1.01847 0.196291 -1.06811
Input 2: -0.105749 -0.0730552 -0.114734 0.471063 0.449806 0.170216 -0.419871 0.445173 -0.160645 -0.469604
Input 3: 0.58114 -0.190553 -0.177266 -0.4043 -0.254952 0.723769 -0.123233 -0.276571 -0.0962605 0.00533618
Input 4: -0.0381991 0.419411 0.470254 0.533402 0.554603 -0.00222986 -0.579875 0.553145 0.380741 -0.636529
Input 5: -0.431335 0.134191 0.178502 0.430547 0.264066 -0.475869 -0.0565757 0.272153 0.176835 -0.115232
Input 6: 0.251853 -0.620661 -0.85112 0.235264 0.288059 0.289046 -0.215913 0.308561 -0.779344 -0.25184
Input 7: -0.0544173 0.868915 1.07764 0.460425 0.403878 -0.379216 0.0118222 0.394789 1.00132 -0.0793184
Input 8: -0.0714138 0.949216 1.2481 0.147089 0.00561479 -0.735631 0.512507 -0.00358031 1.1983 0.420749
Input 9: -1.28967 -0.195232 -0.514298 1.07139 0.861152 -0.587714 -0.9355 0.878449 -0.57166 -1.02425
Input 10: 0.000391075 -0.315036 -0.24267 -0.919569 -1.02692 -0.448597 0.986832 -1.01813 -0.133106 1.0863
Input 11: -0.624939 -0.192645 -0.129645 -0.298204 -0.545523 -1.07382 0.932504 -0.521877 -0.00873052 0.916557
Input 12: -1.17466 0.0295226 -0.0705904 0.638782 0.313347 -1.36283 0.250188 0.333472 -0.0962326 0.0615935
Input 13: 0.0973158 -0.240951 -0.267657 -0.356629 -0.314326 0.10152 0.326649 -0.31364 -0.206842 0.368183
Input 14: -0.0710248 -0.133879 -0.178005 -0.025927 0.016983 -0.0421141 0.0722085 0.0184679 -0.155222 0.0638556
Input 15: -0.718259 0.311627 0.367885 0.191986 0.0421624 -0.539408 0.0802223 0.0266959 0.354905 0.0668109
Input 16: 0.197178 -0.704716 -0.902764 -0.395167 -0.255666 0.597439 -0.304003 -0.251827 -0.858926 -0.210146
Input 17: -0.0964348 -0.955265 -1.26515 -0.0505231 0.0533122 0.60179 -0.563991 0.0631326 -1.21089 -0.489154
Input 18: -0.19826 0.530924 0.702301 0.664638 0.642704 -0.527513 -0.219714 0.653281 0.644297 -0.308954
Input 19: 0.217253 0.0926069 0.129885 -0.0842938 -0.0280644 0.166081 0.010186 -0.0293143 0.119355 0.0263763
Input 20: 0.0140731 0.0166146 0.0493604 0.116992 0.0962944 -0.121894 0.111608 0.102711 0.060773 0.100809
Input 21: 0.0176604 0.0837781 0.122987 0.4526 0.492996 -0.106346 -0.191875 0.508391 0.0884787 -0.239884
Input 22: 0.198638 0.152172 0.180795 0.0356693 0.121913 0.224223 -0.204577 0.118594 0.151107 -0.196389
Input 23: 0.155526 0.104148 0.137977 0.0643445 0.116593 0.115496 -0.0986871 0.117303 0.118542 -0.095296
Input 24: 0.0972008 0.199438 0.295665 0.191736 0.231563 -0.153536 -0.0760051 0.235906 0.249143 -0.10169
Input 25: 0.197697 0.0107412 0.0184693 -0.0301343 0.0382959 0.16781 -0.0400123 0.0384208 0.00814898 -0.0317859
Input 26: 0.159627 0.00431436 0.00844912 0.00807821 0.0548657 0.100086 0.00141806 0.0569412 0.000538483 0.00694467

Hidden layer bias: 
-0.45934 -0.32746 -0.36855 -0.0444234 -0.251436 -0.557395 0.493545 -0.240075 -0.301953 0.472533

Hidden to output weights: 
Hidden 0: -0.251425 1.20366 0.241954 0.327074
Hidden 1: -0.100046 -0.511373 -0.268092 1.44193
Hidden 2: 0.0682531 -0.361044 -0.620458 1.46183
Hidden 3: -0.208261 -1.4524 1.00691 1.01359
Hidden 4: -0.193857 -1.33954 1.27472 1.04063
Hidden 5: -0.628831 0.917072 1.33879 0.273386
Hidden 6: 0.464109 0.22705 -1.48037 -0.74329
Hidden 7: -0.166268 -1.34986 1.29878 1.01446
Hidden 8: 0.137648 -0.314737 -0.638192 1.32764
Hidden 9: 0.480144 0.536617 -1.54049 -0.813507

Output layer bias: 
1.32965 -0.227525 0.237038 0.302806

Tue Sep 12 22:14:10 2017

Input to hidden weights: 
Input 0: 0.0377235 -0.0888213 -0.865768 -1.21402 -0.373584 1.44376 -0.314982 0.667805 -0.712922 1.2818
Input 1: 0.147466 0.185568 0.603726 0.842055 0.338176 -1.03822 0.314369 -0.877362 0.944986 -1.05686
Input 2: 0.0121197 -0.137149 0.266727 0.369779 -0.136418 -0.45274 -0.151509 -0.486274 0.477745 -0.458959
Input 3: 0.732812 -0.133412 0.442095 0.132153 -0.215734 0.129828 -0.195024 0.552329 -0.512201 0.139053
Input 4: -0.129699 0.274184 0.346901 0.540799 0.477871 -0.653996 0.464143 -0.559762 0.54761 -0.646237
Input 5: -0.59007 0.16054 -0.0926423 0.0402184 0.181779 -0.183954 0.186527 -0.493923 0.391497 -0.181067
Input 6: 0.399228 -0.512803 0.26073 0.224757 -0.864398 -0.225632 -0.858005 -0.143741 0.24015 -0.323363
Input 7: -0.301211 0.805807 -0.108796 0.0283581 1.10781 -0.127458 1.10624 -0.542729 0.519013 -0.197461
Input 8: -0.548446 0.933304 -0.441699 -0.419402 1.26587 0.333709 1.27638 -0.267709 0.196814 0.263793
Input 9: -1.20942 -0.262538 0.164039 0.718168 -0.430547 -1.08835 -0.461148 -1.21503 1.06974 -0.970319
Input 10: -0.276336 -0.128768 -0.645245 -0.872917 -0.274128 1.02808 -0.245669 0.853081 -0.943927 1.05749
Input 11: -0.987662 0.0771495 -0.91867 -0.879892 -0.12475 0.806944 -0.0860286 0.205562 -0.335695 0.792134
Input 12: -1.46545 0.0596519 -0.698243 -0.29705 -0.0762344 -0.118884 -0.0791563 -0.875367 0.666904 -0.106454
Input 13: 0.243696 -0.134162 -0.144767 -0.29944 -0.261115 0.387395 -0.251779 0.423059 -0.371484 0.377134
Input 14: 0.0203061 -0.0848552 -0.120409 -0.0808386 -0.194079 0.0849506 -0.19034 0.0596328 -0.00653134 0.0551391
Input 15: -0.780662 0.27572 -0.264256 -0.119445 0.365929 0.0141667 0.368928 -0.291535 0.146862 0.0932413
Input 16: 0.519958 -0.710322 0.380312 0.243938 -0.925148 -0.14315 -0.929171 0.526313 -0.476038 -0.0522569
Input 17: 0.370643 -0.937526 0.420155 0.448471 -1.29684 -0.406912 -1.30616 0.172065 -0.135421 -0.324332
Input 18: -0.397803 0.553733 -0.0654248 0.190419 0.717428 -0.328594 0.718508 -0.623984 0.649401 -0.387165
Input 19: 0.212423 0.0816119 0.0779937 0.0249021 0.14799 0.0266267 0.145181 0.0920337 -0.0441676 0.011391
Input 20: -0.0733634 0.0947711 -0.113325 -0.0697605 0.0741404 0.0723845 0.0776803 -0.150638 0.170031 0.0292941
Input 21: 0.0129186 0.0813105 0.0310113 0.189388 0.13781 -0.236138 0.131423 -0.328286 0.467308 -0.302849
Input 22: 0.250235 0.108626 0.21381 0.204264 0.202623 -0.18428 0.197189 0.00340586 0.0453627 -0.181091
Input 23: 0.144535 0.101863 0.0901607 0.107227 0.165135 -0.088291 0.161369 -0.0443783 0.0872771 -0.100282
Input 24: -0.0495804 0.191595 -0.0547636 0.0563185 0.302333 -0.0781118 0.298428 -0.142344 0.195602 -0.106522
Input 25: 0.219844 0.00222614 0.0940814 0.0614712 0.0320907 -0.0340266 0.0269238 0.0493688 0.0176442 -0.0496483
Input 26: 0.154787 0.00982483 0.0357948 0.0224722 0.0233487 0.00423514 0.0199763 -0.00185606 0.0591745 -0.0203339

Hidden layer bias: 
-0.616628 -0.205238 -0.533525 -0.483223 -0.410475 0.436528 -0.395459 -0.0491608 -0.0548688 0.42093

Hidden to output weights: 
Hidden 0: -0.620789 0.951329 1.12579 0.26255
Hidden 1: 0.0608356 -0.485078 -0.365613 1.19837
Hidden 2: -0.388622 0.0878343 0.964147 0.665957
Hidden 3: -0.321223 -0.30023 1.26608 0.722226
Hidden 4: -0.0484229 -0.468632 -0.629375 1.51139
Hidden 5: 0.46866 0.853735 -1.50451 -0.852987
Hidden 6: -0.00322805 -0.461002 -0.657114 1.48761
Hidden 7: 0.107353 1.58616 -0.618428 -1.04603
Hidden 8: -0.0251691 -1.57994 0.931778 1.02341
Hidden 9: 0.338583 1.05449 -1.50796 -0.875584

Output layer bias: 
1.58964 -0.106688 0.305394 0.194427

Tue Sep 12 22:29:03 2017

Input to hidden weights: 
Input 0: 0.59878 1.08176 0.243811 0.314133 1.13359 0.0731909 -0.249692 -1.57064 -0.679015 -0.7714
Input 1: -0.435369 -1.06595 -0.188129 -0.298582 -1.09456 -0.098871 0.244009 1.08154 0.69675 0.940217
Input 2: 0.0564384 -0.456264 0.394673 0.237513 -0.464535 0.0177993 0.181426 0.423477 0.312922 0.476987
Input 3: 0.177657 0.0596292 0.1022 0.140313 0.0701072 0.0715723 0.996338 -0.0556646 0.100343 -0.371562
Input 4: -0.409147 -0.572298 -0.374985 -0.420082 -0.592895 -0.0699864 -0.179393 0.635183 0.415549 0.524876
Input 5: -0.0908148 -0.199564 -0.170774 -0.160078 -0.216081 0.0264425 -0.73506 0.208344 0.211453 0.436398
Input 6: 0.533202 -0.28662 0.588713 0.702188 -0.350091 0.0490332 0.313065 0.36928 0.00170971 0.215025
Input 7: -0.757919 -0.31473 -1.03669 -1.00694 -0.289949 -0.120779 -0.602566 0.0784325 0.369708 0.400915
Input 8: -0.763047 0.120899 -1.23163 -1.15891 0.168756 -0.0998364 -0.982572 -0.459525 0.149518 0.0765307
Input 9: 0.108682 -0.891497 0.514154 0.471597 -0.941376 0.178415 -1.11339 1.2092 0.578788 1.1658
Input 10: 0.44041 1.07783 0.124712 0.251183 1.09845 0.098668 -0.37371 -1.05823 -0.731022 -0.927234
Input 11: 0.327419 0.723389 -0.133586 0.0625347 0.720248 0.0936111 -1.32049 -0.747229 -0.527251 -0.303299
Input 12: 0.0933987 -0.0910136 0.169874 0.14932 -0.0941093 0.103191 -1.79921 0.0363325 -0.0579441 0.59754
Input 13: 0.219378 0.302148 0.165495 0.2138 0.312453 0.0196887 0.283581 -0.328472 -0.25795 -0.34637
Input 14: 0.160864 0.00876665 0.18786 0.196686 0.00812326 0.00636827 -0.000160088 -0.0474423 -0.12647 -0.0317832
Input 15: -0.19847 0.00525098 -0.125517 -0.241289 0.0570792 0.117393 -0.699802 -0.142103 0.170203 0.230216
Input 16: 0.587077 0.101617 0.875391 0.838304 0.0730683 0.0826339 0.868186 0.200192 -0.24183 -0.340356
Input 17: 0.813362 -0.170394 1.28107 1.20718 -0.221013 0.131065 0.774155 0.528406 -0.129058 0.01635
Input 18: -0.428097 -0.512972 -0.615077 -0.577592 -0.543104 -0.198243 -0.790187 0.474382 0.219724 0.597768
Input 19: -0.125637 0.0111117 -0.15025 -0.1484 0.0122207 -0.0533192 0.218765 -0.0220705 -0.000863349 -0.0843257
Input 20: -0.0335724 -0.0328957 -0.0809833 -0.0631185 -0.0390658 -0.0569604 -0.198962 -0.0205027 -0.00744713 0.101569
Input 21: -0.0707359 -0.388348 -0.0508803 -0.056426 -0.430874 -0.133321 -0.205552 0.392156 0.0858556 0.434781
Input 22: -0.183257 -0.168911 -0.192412 -0.194009 -0.173419 -0.0606815 0.269285 0.206556 0.102539 0.0403812
Input 23: -0.125176 -0.113362 -0.148364 -0.142973 -0.119235 -0.0704268 0.10295 0.12109 0.0499555 0.0606765
Input 24: -0.180176 -0.180447 -0.240519 -0.232038 -0.196933 -0.145701 -0.282629 0.182372 0.0316808 0.170634
Input 25: -0.0619206 -0.0642139 -0.0427331 -0.0479745 -0.07084 -0.0429112 0.252323 0.0767566 0.0179673 -0.0159933
Input 26: -0.0506447 -0.0560153 -0.0348124 -0.0353608 -0.0614654 -0.047651 0.146052 0.0432331 0.0112789 0.0124837

Hidden layer bias: 
0.404623 0.377089 0.399514 0.40875 0.384757 0.115951 -0.716601 -0.464088 -0.241918 -0.0503994

Hidden to output weights: 
Hidden 0: 0.357686 0.284867 0.159474 -1.37671
Hidden 1: 0.270854 1.17566 -1.41806 -1.0869
Hidden 2: -0.00449527 0.33358 0.67635 -1.40949
Hidden 3: 0.0971668 0.285021 0.62404 -1.42981
Hidden 4: 0.225784 1.20753 -1.55889 -1.04475
Hidden 5: -0.326249 -0.33661 -0.347675 -0.60513
Hidden 6: -1.09911 1.27888 1.36097 0.0599687
Hidden 7: -0.340901 -0.940311 1.90994 0.894079
Hidden 8: -0.653505 -1.0769 0.446349 1.16848
Hidden 9: 0.023692 -1.50486 1.21331 1.0122

Output layer bias: 
1.74209 -0.391976 0.439101 0.297412

Wed Sep 13 00:16:30 2017

Input to hidden weights: 
Input 0: 0.368308 -0.262858 -0.448487 -0.369261 1.48278 0.983057 -1.1561 -1.00233 -0.151409 -0.861554
Input 1: -0.348108 0.340905 0.349621 0.384384 -1.07439 -1.03697 1.06343 0.631263 0.198004 0.967965
Input 2: -0.0500751 -0.101696 0.177877 -0.0405351 -0.457393 -0.457811 0.46164 0.292596 -0.29383 0.550585
Input 3: -0.00252699 -0.215663 0.64599 -0.225026 0.120676 0.210841 -0.139708 0.663995 -0.197973 -0.861854
Input 4: -0.360394 0.450658 0.0411943 0.422447 -0.655428 -0.593747 0.626399 0.361358 0.391265 0.626395
Input 5: -0.253397 0.173718 -0.437947 0.137935 -0.165641 -0.240308 0.199464 -0.126729 0.186525 0.653875
Input 6: 0.210638 -0.739287 0.293124 -0.608707 -0.134576 -0.339455 0.337469 0.324762 -0.619319 0.132379
Input 7: -0.563063 0.992453 -0.288678 0.868877 -0.180052 -0.345479 0.264823 -0.197332 1.03259 0.549919
Input 8: -0.522016 1.11166 -0.656755 0.926495 0.334319 0.109404 -0.226645 -0.577628 1.20966 0.26651
Input 9: -0.319384 -0.428089 -0.492141 -0.232319 -1.14144 -0.951525 0.985017 0.187869 -0.508902 1.74716
Input 10: 0.350256 -0.300765 -0.491207 -0.365518 1.08472 1.05766 -1.08404 -0.682766 -0.138377 -0.936566
Input 11: 0.139445 -0.16631 -1.06335 -0.239776 0.836112 0.61919 -0.729419 -1.09221 0.0805817 -0.044496
Input 12: -0.0774103 -0.0170177 -1.25418 0.0413423 -0.0988267 -0.215028 0.11945 -0.911747 -0.0279858 1.32362
Input 13: 0.24783 -0.251985 0.0844156 -0.234982 0.375011 0.347855 -0.360782 -0.139287 -0.192256 -0.506351
Input 14: 0.160439 -0.18355 -0.0152847 -0.144062 0.0425998 -0.0115475 -0.00494048 -0.161889 -0.17293 -0.0576595
Input 15: -0.313666 0.338933 -0.554254 0.306807 -0.10469 0.00475316 -0.0346407 -0.291329 0.198066 0.476995
Input 16: 0.478345 -0.826609 0.518454 -0.707193 -0.0913925 0.183897 -0.0515001 0.522234 -0.882313 -0.57572
Input 17: 0.49681 -1.14127 0.541013 -0.947596 -0.40854 -0.163706 0.289101 0.556497 -1.24494 -0.113984
Input 18: -0.222044 0.642018 -0.369472 0.554013 -0.384711 -0.551995 0.472467 -0.234929 0.703995 0.721579
Input 19: -0.00614005 0.131987 0.156353 0.109512 0.0162051 0.0116433 -0.00697696 0.0929891 0.13605 -0.161036
Input 20: -0.0018373 0.0713138 -0.0895746 0.054885 0.0444858 -0.0759872 0.0243605 -0.16198 0.099018 0.139406
Input 21: -0.00113298 0.124007 -0.0507612 0.110169 -0.292593 -0.468574 0.405785 -0.0966067 0.134329 0.399262
Input 22: -0.0628078 0.17945 0.232482 0.163861 -0.188915 -0.130833 0.15943 0.242184 0.176025 -0.0698034
Input 23: -0.0254153 0.144383 0.132039 0.126057 -0.101509 -0.108407 0.107164 0.0805927 0.154107 -0.00386175
Input 24: 0.00337291 0.269631 -0.0751515 0.220221 -0.109187 -0.169116 0.13993 -0.155567 0.295344 0.0827167
Input 25: 0.0165535 0.0308339 0.152861 0.0280931 -0.03414 -0.0484477 0.0480961 0.0980736 0.0283891 -0.112322
Input 26: 0.0190077 0.0309931 0.0956401 0.0279199 0.0013195 -0.0486995 0.0308957 0.0164855 0.0370248 -0.048611

Hidden layer bias: 
0.152917 -0.372152 -0.559999 -0.350288 0.443364 0.283173 -0.359733 -0.623519 -0.355135 0.200581

Hidden to output weights: 
Hidden 0: 0.487221 0.98955 0.127027 -1.17607
Hidden 1: -0.0768996 -0.48467 -0.587362 1.39311
Hidden 2: -0.821944 0.61513 1.31938 0.331551
Hidden 3: -0.150469 -0.567285 -0.351598 1.38173
Hidden 4: 0.467996 0.97477 -1.61606 -0.88816
Hidden 5: 0.101847 1.3598 -1.50402 -0.892794
Hidden 6: -0.212982 -1.22354 1.60455 0.860431
Hidden 7: -0.711159 0.144569 1.01467 0.567853
Hidden 8: 0.0460188 -0.467233 -0.651287 1.31007
Hidden 9: 0.511269 -1.715 0.635344 0.873349

Output layer bias: 
1.7762 -0.173889 0.456445 0.182597

Wed Sep 13 03:24:27 2017

Input to hidden weights: 
Input 0: 0.627263 -0.501246 -1.56601 -0.448417 -0.494976 -0.188785 -0.70568 -0.640925 -1.28531 1.10325
Input 1: -0.740435 0.267147 0.934273 0.399551 0.408991 0.259093 0.891108 0.761386 0.816715 -1.03139
Input 2: -0.321606 -0.454294 0.415674 -0.137305 -0.0514766 0.164422 0.509859 0.329639 0.377431 -0.444268
Input 3: 0.0920369 -0.26885 0.00958167 -0.21668 -0.154037 0.78336 -0.738145 -0.132106 0.213314 0.272501
Input 4: -0.454319 0.496635 0.605473 0.451654 0.36908 -0.111607 0.615315 0.463985 0.523995 -0.634617
Input 5: -0.195097 0.149791 0.12641 0.124303 0.0879071 -0.596781 0.6101 0.193202 0.00904692 -0.250011
Input 6: -0.0181182 -0.667452 0.364284 -0.693076 -0.382647 0.371482 0.195995 0.0241001 0.344373 -0.490364
Input 7: -0.438753 1.16777 -0.122174 0.955582 0.686376 -0.448284 0.516805 0.445861 -0.128879 -0.229347
Input 8: -0.201076 1.28111 -0.64612 1.0023 0.647266 -0.734122 0.265772 0.196045 -0.611005 0.227887
Input 9: -0.573137 -0.497572 1.16243 -0.323671 0.0264562 -1.00471 1.44248 0.595123 0.749154 -0.964588
Input 10: 0.767275 -0.225 -0.923795 -0.376918 -0.408331 -0.385626 -0.849805 -0.7859 -0.844519 1.01861
Input 11: 0.510415 0.0270188 -0.827606 -0.223064 -0.247328 -1.16423 -0.0879844 -0.511146 -0.925672 0.61699
Input 12: -0.163654 -0.149724 -0.0540111 -0.0581231 0.0665022 -1.52096 1.13414 0.209074 -0.387276 -0.227677
Input 13: 0.278341 -0.228687 -0.333911 -0.232618 -0.185633 0.213316 -0.490829 -0.279641 -0.273973 0.369185
Input 14: 0.0591532 -0.21463 -0.067282 -0.163275 -0.0813617 -0.0170627 -0.0862442 -0.0434684 -0.064911 0.0175011
Input 15: -0.215459 0.0898149 -0.153918 0.288253 0.252995 -0.75927 0.352604 0.221433 -0.236351 0.204502
Input 16: 0.302766 -0.95097 0.419454 -0.768833 -0.519489 0.676679 -0.524425 -0.306018 0.427031 0.043742
Input 17: 0.166312 -1.35946 0.722326 -1.04956 -0.657023 0.559267 -0.135426 -0.158277 0.650115 -0.275266
Input 18: -0.327977 0.806385 0.267147 0.644954 0.4375 -0.508643 0.641986 0.357842 0.173219 -0.552964
Input 19: 0.00669476 0.192959 -0.0271762 0.144483 0.0780925 0.199067 -0.126418 -0.00715034 0.0175918 0.000838148
Input 20: -0.0224241 0.119879 -0.0975778 0.0879458 0.0373064 -0.126138 0.152148 0.0327198 -0.094844 -0.0730876
Input 21: -0.158608 0.19313 0.240077 0.134422 0.0665283 -0.0710226 0.396665 0.185372 0.195372 -0.509468
Input 22: -0.103849 0.260181 0.199534 0.205864 0.151911 0.2512 -0.0430845 0.107046 0.21581 -0.154769
Input 23: -0.0647369 0.223478 0.0962119 0.169146 0.106519 0.135006 0.0145199 0.0710941 0.111818 -0.123727
Input 24: -0.0529285 0.382491 0.0904029 0.285162 0.13493 -0.0899758 0.0994472 0.0673097 0.0718122 -0.202479
Input 25: -0.012756 0.0855121 0.0485646 0.0618945 0.0305821 0.223528 -0.0776649 0.0154695 0.0635 -0.0835223
Input 26: -0.0155404 0.0903642 0.00532509 0.0643234 0.0313339 0.147118 -0.0240609 0.0210663 0.0202727 -0.0770563

Hidden layer bias: 
0.240817 -0.539645 -0.471552 -0.432505 -0.338728 -0.626509 0.141897 -0.242015 -0.51366 0.332943

Hidden to output weights: 
Hidden 0: 0.535045 1.05951 -0.569816 -1.18388
Hidden 1: -0.0785548 -0.469491 -0.711069 1.66868
Hidden 2: -0.415114 -0.36206 1.71405 0.653701
Hidden 3: -0.0869494 -0.523343 -0.424378 1.5866
Hidden 4: -0.180342 -0.685342 -0.039587 1.46005
Hidden 5: -0.735371 1.06618 1.21681 0.156604
Hidden 6: 0.233226 -1.54793 0.720992 0.969504
Hidden 7: -0.486738 -1.08728 0.61135 1.19035
Hidden 8: -0.312324 -0.0450952 1.52489 0.665391
Hidden 9: 0.00719411 1.21277 -1.68926 -0.849436

Output layer bias: 
1.48031 -0.110006 0.694617 0.139562

Wed Sep 13 03:24:46 2017

Input to hidden weights: 
Input 0: 0.825481 -0.611268 -0.285714 -0.900527 -1.57243 -0.583294 -0.612102 0.922291 1.01887 0.186361
Input 1: -0.932259 0.768545 0.282325 0.821262 0.823354 0.835128 0.405059 -0.866184 -0.948088 0.05923
Input 2: -0.413333 0.432347 -0.255739 0.331408 0.3057 0.411068 -0.0810837 -0.350279 -0.39073 0.0288785
Input 3: 0.187274 -0.708008 -0.213908 0.142613 0.256857 -0.397911 -0.285002 -0.0525475 -0.013322 0.638188
Input 4: -0.566972 0.524984 0.516941 0.463755 0.52149 0.518791 0.490276 -0.498831 -0.554111 -0.213494
Input 5: -0.264051 0.621396 0.230931 0.0713751 0.0877336 0.409612 0.118854 -0.100164 -0.117601 -0.668454
Input 6: -0.256678 0.239844 -1.08734 0.143756 0.425177 0.178538 -0.850241 -0.169689 -0.230243 0.353488
Input 7: -0.347413 0.348687 1.36247 0.281699 -0.235703 0.416454 1.0446 -0.304595 -0.29544 -0.292696
Input 8: 0.016668 0.161036 1.64398 -0.045029 -0.836497 0.144627 1.12126 0.0420986 0.0987487 -0.45231
Input 9: -0.731296 1.30729 -0.685907 0.561119 1.17808 0.830593 -0.329655 -0.622128 -0.696526 -1.25977
Input 10: 0.918525 -0.72576 -0.196234 -0.868887 -0.830898 -0.81102 -0.377116 0.90531 0.97674 -0.181113
Input 11: 0.536388 0.0480801 -0.0181315 -0.74948 -0.74495 -0.260378 -0.312679 0.725719 0.770224 -0.924308
Input 12: -0.199143 1.09041 -0.105873 -0.208547 -0.395973 0.526853 -0.1026 0.0998635 0.0692805 -1.36513
Input 13: 0.327665 -0.401267 -0.267863 -0.243749 -0.261845 -0.332216 -0.25993 0.268522 0.301525 0.23186
Input 14: 0.0359545 -0.0782555 -0.230891 -0.0572771 -0.0705341 -0.0435355 -0.186865 0.041833 0.0388592 0.0337436
Input 15: 1.00934e-05 0.263528 0.432275 0.00670592 -0.231315 0.161111 0.292851 -0.0108243 0.0346831 -0.849649
Input 16: 0.196046 -0.376595 -1.15724 -0.0733623 0.506662 -0.361757 -0.841802 0.100801 0.0746001 0.431477
Input 17: -0.0515232 -0.0376375 -1.67842 0.0532382 0.872901 -0.088786 -1.1762 -0.0558117 -0.1177 0.249666
Input 18: -0.505913 0.621998 0.873298 0.196717 0.162617 0.594387 0.6798 -0.274555 -0.331912 -0.451631
Input 19: 0.00245959 -0.127699 0.173642 0.0263642 -0.0179689 -0.0389806 0.169107 -0.0198386 -0.0185496 0.212508
Input 20: -0.0688972 0.101721 0.0676086 -0.0431208 -0.0745701 0.120782 0.0642885 0.0218621 0.0115288 -0.0123319
Input 21: -0.383401 0.407822 0.103388 0.0919976 0.218744 0.457172 0.141416 -0.156909 -0.215182 -0.0830258
Input 22: -0.135308 -0.0573061 0.224075 0.169913 0.210663 0.0545972 0.226741 -0.167603 -0.181392 0.209009
Input 23: -0.104635 -0.0146022 0.169582 0.0826841 0.11575 0.0719342 0.172354 -0.0895457 -0.10385 0.161577
Input 24: -0.162178 0.107438 0.372918 0.020533 0.0775128 0.180526 0.324678 -0.0535734 -0.0829625 0.0253834
Input 25: -0.0596863 -0.0723646 0.0256887 0.0463811 0.0753121 0.0209608 0.0683796 -0.0499614 -0.0605988 0.216152
Input 26: -0.058583 -0.0272301 0.0155506 0.0215472 0.0304468 0.0458036 0.0546694 -0.03048 -0.0400956 0.170736

Hidden layer bias: 
0.291985 0.155017 -0.458325 -0.409934 -0.485559 -0.0897196 -0.473484 0.400806 0.42734 -0.484006

Hidden to output weights: 
Hidden 0: 0.0288232 0.991738 -1.1805 -0.985272
Hidden 1: 0.369677 -1.19438 0.672909 0.703097
Hidden 2: 0.102107 -0.414862 -0.949478 1.65422
Hidden 3: -0.589284 -0.667052 0.808428 1.01506
Hidden 4: -0.493145 -0.076633 1.76269 0.539335
Hidden 5: 0.0912471 -1.17586 0.941671 0.947839
Hidden 6: -0.250765 -0.286199 -0.393292 1.51852
Hidden 7: 0.462398 0.73509 -0.891733 -1.02543
Hidden 8: 0.370011 0.75608 -1.07936 -1.01198
Hidden 9: -0.635834 1.11715 0.78032 0.0569361

Output layer bias: 
1.40074 -0.061815 0.325447 0.125444

Wed Sep 13 03:24:55 2017

Input to hidden weights: 
Input 0: 0.777829 -0.798893 -0.946862 -0.687059 -0.0257167 0.646105 -0.681009 -0.0814577 1.29584 -1.20631
Input 1: -0.833985 0.850852 0.881264 0.802544 0.120697 -0.46281 0.802987 0.30281 -0.808382 0.905065
Input 2: -0.368642 0.373632 0.370189 0.372493 -0.0123442 -0.0226997 0.375687 -0.242674 -0.319228 0.36856
Input 3: 0.149416 -0.163967 -0.124027 -0.19553 1.04041 0.169469 -0.228585 -0.195624 -0.169611 0.0101937
Input 4: -0.462275 0.475483 0.505499 0.447306 -0.190976 -0.370647 0.451865 0.508517 -0.475444 0.530465
Input 5: -0.209918 0.217234 0.177884 0.256582 -0.737729 -0.0709364 0.274756 0.274133 0.00503701 0.0827598
Input 6: -0.187601 0.214421 0.272446 0.1481 0.338676 0.502075 0.160233 -1.24959 -0.158233 0.238524
Input 7: -0.348173 0.341402 0.266309 0.389618 -0.462717 -0.751753 0.389628 1.57475 -0.0196295 0.145356
Input 8: -0.0339194 0.0170147 -0.0990973 0.105551 -0.715056 -0.718259 0.105457 1.94262 0.406643 -0.269648
Input 9: -0.741765 0.762335 0.784278 0.76257 -1.31938 0.00529655 0.786528 -0.926341 -0.788059 0.826246
Input 10: 0.835736 -0.84743 -0.879146 -0.798153 -0.243921 0.454418 -0.793724 -0.16599 0.852674 -0.923936
Input 11: 0.478459 -0.476921 -0.557022 -0.39967 -1.10596 0.366686 -0.373306 0.0442728 0.819887 -0.747754
Input 12: -0.223301 0.233467 0.135307 0.319311 -1.87566 0.0305769 0.359337 -0.079442 0.348694 -0.0854115
Input 13: 0.25365 -0.258357 -0.271275 -0.254065 0.264305 0.179169 -0.259651 -0.233423 0.246212 -0.283432
Input 14: -0.00739586 0.0104173 0.0041646 0.0029944 -0.0359058 0.107454 0.0038659 -0.219853 0.0457473 -0.0241768
Input 15: -0.0719908 0.0509491 -0.0475402 0.143093 -0.833181 -0.214201 0.140431 0.549786 0.102865 -0.0953304
Input 16: 0.205674 -0.195242 -0.0847845 -0.274397 0.686228 0.574236 -0.282213 -1.35886 -0.236371 0.0965516
Input 17: -0.0172877 0.0366769 0.148347 -0.0446301 0.473526 0.745511 -0.0417398 -1.96042 -0.420506 0.3084
Input 18: -0.47336 0.494199 0.464558 0.492382 -0.657299 -0.481173 0.513436 1.01885 -0.189276 0.330881
Input 19: 0.0268926 -0.0256155 -0.0135196 -0.0389623 0.26198 -0.097849 -0.0429208 0.163169 -0.0204903 0.00124286
Input 20: -0.0396632 0.0461629 0.023987 0.0553209 -0.0981399 -0.0290069 0.0637877 0.0698744 0.085692 -0.0456914
Input 21: -0.318928 0.345446 0.343068 0.318763 -0.152625 -0.0927777 0.341979 0.121566 -0.159155 0.240868
Input 22: -0.108221 0.111979 0.139208 0.0841832 0.281027 -0.174026 0.0791269 0.232076 -0.198802 0.181112
Input 23: -0.0767726 0.0827187 0.0934026 0.0660047 0.167869 -0.124104 0.0658029 0.17925 -0.10244 0.09943
Input 24: -0.152996 0.166146 0.167835 0.152376 -0.133045 -0.203667 0.162295 0.417207 -0.0843094 0.124472
Input 25: -0.0301589 0.0359674 0.0510173 0.016227 0.257087 -0.0441194 0.0152632 -0.00251186 -0.0625479 0.0555232
Input 26: -0.0323824 0.0381623 0.042512 0.0254462 0.179597 -0.0375387 0.0268773 -0.0110325 -0.0276096 0.0294721

Hidden layer bias: 
0.242455 -0.246085 -0.312489 -0.179386 -0.692206 0.383835 -0.16318 -0.463835 0.477955 -0.427311

Hidden to output weights: 
Hidden 0: 0.231931 1.00275 -0.946897 -0.965504
Hidden 1: -0.190083 -1.01821 1.01435 0.946994
Hidden 2: -0.158138 -0.891826 1.19165 0.882906
Hidden 3: -0.256129 -1.08539 0.825657 0.993044
Hidden 4: -0.909412 1.3292 1.10325 0.278993
Hidden 5: 0.249978 0.390375 -0.0365448 -1.47873
Hidden 6: -0.212506 -1.10672 0.852297 0.968025
Hidden 7: 0.200402 -0.389911 -1.35195 1.88933
Hidden 8: 0.422501 0.1313 -1.31529 -0.778972
Hidden 9: -0.31148 -0.534152 1.29907 0.838459

Output layer bias: 
1.78113 -0.342107 0.373847 0.0724381

